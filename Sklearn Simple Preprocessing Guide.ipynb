{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Categorical data with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [['male', 'from US', 'uses Coinbase'], ['female', 'from UK', 'uses Binance']]\n",
    "encode = preprocessing.OrdinalEncoder()\n",
    "encode.fit(X)\n",
    "\n",
    "encode.transform([['male', 'from UK', 'uses Coinbase']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = preprocessing.OneHotEncoder()\n",
    "one_hot.fit(X)\n",
    "\n",
    "one_hot.transform([['male', 'from UK', 'uses Coinbase'],\n",
    "                   ['female', 'from US', 'uses Binance']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from UK', 'from US'], dtype=object),\n",
       " array(['uses Binance', 'uses Coinbase'], dtype=object)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling data with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72478401, 0.22285347, 0.94969243, 0.81965177],\n",
       "       [0.08764589, 0.6394406 , 0.37524133, 0.05781259],\n",
       "       [0.51633396, 0.11856665, 0.26239836, 0.41984248]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = np.random.rand(3,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20176096,  1.41156087, -0.94728207, -0.68150144],\n",
       "       [-1.11133624, -0.6308009 , -0.43575025, -0.73240669],\n",
       "       [ 1.3130972 , -0.78075997,  1.38303232,  1.41390814]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scaled mean is: [ 0.00000000e+00  1.85037171e-16  2.22044605e-16 -7.40148683e-17]\n",
      "The scaled variance is: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(f'The scaled mean is: {X_scaled.mean(axis=0)}\\nThe scaled variance is: {X_scaled.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25424326, 0.84816742, 0.40149539, 0.23403812],\n",
       "       [0.17532072, 0.5339978 , 0.74954022, 0.34971197],\n",
       "       [0.3618432 , 0.20896422, 0.47882843, 0.77209248]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = preprocessing.Normalizer()\n",
    "\n",
    "X_norm = norm.transform(X)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating Missing Values with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10. ,  6.5],\n",
       "       [ 2. ,  4. ],\n",
       "       [10. ,  9. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imputer.fit_transform([[10,np.nan],[2,4],[10,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['i', 'g'],\n",
       "       ['o', 'r'],\n",
       "       ['i', 'r'],\n",
       "       ['i', 'r']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([['i', 'g'],\n",
    "                   ['o', 'r'],\n",
    "                   ['i', np.nan],\n",
    "                   [np.nan, 'r']], dtype='category')\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False,  True],\n",
       "       [False, False],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "# Image the 3's were imputed by the SimpleImputer()\n",
    "Y = np.array([[3,1], \n",
    "              [5,3],\n",
    "              [9,4], \n",
    "              [3,7]])\n",
    "\n",
    "missing = MissingIndicator(missing_values=3)\n",
    "missing.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 5.        ],\n",
       "       [4.        , 6.        ],\n",
       "       [2.        , 6.33291692],\n",
       "       [2.42391423, 8.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=15, random_state=42)\n",
    "imputer.fit_transform(([1,5],[4,6],[2, np.nan], [np.nan, 8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sample in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training set (1200, 2)\n",
      "X testing set (300, 2)\n",
      "y training set (1200,)\n",
      "y testing set (300,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a random dataset\n",
    "X, y = make_blobs(n_samples=1500)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "print(f'X training set {X_train.shape}\\nX testing set {X_test.shape}\\ny training set {y_train.shape}\\ny testing set {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of y before splitting is Counter({0: 950, 1: 50})\n",
      "Number of y in the training set after splitting is Counter({0: 757, 1: 43})\n",
      "Number of y in the testing set after splitting is Counter({0: 193, 1: 7})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "\n",
    "# Create an imablanced dataset\n",
    "X, y = make_classification(n_samples=1000, weights=[0.95], flip_y=0, random_state=42)\n",
    "print(f'Number of y before splitting is {Counter(y)}')\n",
    "\n",
    "# Split the data the usual way\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print(f'Number of y in the training set after splitting is {Counter(y_train)}')\n",
    "print(f'Number of y in the testing set after splitting is {Counter(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of y in the training set after splitting is Counter({0: 760, 1: 40})\n",
      "Number of y in the testing set after splitting is Counter({0: 190, 1: 10})\n"
     ]
    }
   ],
   "source": [
    "# Split the data by stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)\n",
    "print(f'Number of y in the training set after splitting is {Counter(y_train)}')\n",
    "print(f'Number of y in the testing set after splitting is {Counter(y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
